## Progress
This version of the project integrates an LLM inference service using MistralRS.
The basic functionality has been implemented and tested.

## References 
This project uses the open-source MistralRS crate (MIT License):
 -- MistralRS GitHub: https://github.com/EricLBuehler/mistral.rs
We thank the MistralRS contributors for providing an efficient Rust-based LLM runtime.
